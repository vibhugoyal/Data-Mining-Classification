{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "\n",
    "#Reading the CSV file and storing it in the data frame object named df\n",
    "\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data\",names=['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling\n",
    "del df['Fe']\n",
    "del df['Ba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca  class\n",
       "1    1.52101  13.64  4.49  1.10  71.78  0.06  8.75      1\n",
       "2    1.51761  13.89  3.60  1.36  72.73  0.48  7.83      1\n",
       "3    1.51618  13.53  3.55  1.54  72.99  0.39  7.78      1\n",
       "4    1.51766  13.21  3.69  1.29  72.61  0.57  8.22      1\n",
       "5    1.51742  13.27  3.62  1.24  73.08  0.55  8.07      1\n",
       "..       ...    ...   ...   ...    ...   ...   ...    ...\n",
       "210  1.51623  14.14  0.00  2.88  72.61  0.08  9.18      7\n",
       "211  1.51685  14.92  0.00  1.99  73.06  0.00  8.40      7\n",
       "212  1.52065  14.36  0.00  2.02  73.42  0.00  8.44      7\n",
       "213  1.51651  14.38  0.00  1.94  73.61  0.00  8.48      7\n",
       "214  1.51711  14.23  0.00  2.08  73.36  0.00  8.62      7\n",
       "\n",
       "[214 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "n= df.shape[0]  ## n denotes no. of rows or data instances\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "y = df['class']\n",
    "X = df.drop('class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb=GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred=gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  0,  0,  0,  0,  0],\n",
       "       [21,  2,  0,  0,  2,  0],\n",
       "       [ 2,  0,  1,  0,  0,  0],\n",
       "       [ 0,  2,  0,  3,  0,  4],\n",
       "       [ 0,  0,  0,  0,  3,  0],\n",
       "       [ 0,  1,  0,  0,  3,  4]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68, 0.5, 'predicted label')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAEGCAYAAACHNTs8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAba0lEQVR4nO3deXxV5Z3H8c/vJgEhuKNAQhQUR6V1qxDX+sJ2BMay1DpFqahjW3EGbWFasbZipTOCM1IXFKuiFjeoMs6obCJCUcABWRSRJBRIg5AQcakbS8eQ/OaPe0MDhySX3Nx7Dsn3/XrllXvuzTnPNw/6y9me55i7IyJSVyzsACISPSoMIhKgwiAiASoMIhKgwiAiAdlhB6jPrqd/GanLJdmXXh92hL30PPX7YUfYS9nnH4QdQZpg91cVtr/3tccgIgEqDCISoMIgIgEqDCISoMIgIgEqDCISoMIgIgEqDCISoMIgIgEqDCISoMIgIgEqDCISoMIgIgEtqjDcMXMVF983m8snz9/z3i3/8xZDHlvAkMcW8A+T5jLksQUZy1O57SOuu+kXDPzBcAZfdQPPTH8JgFf/uJjBV93AaRdeytqS9RnLU1fnvE488+KjzH3zBeYsns61w4eGkmNf/fr2oWjtItYVL+GW0TeGHafV5onssOumGHTG8VzZ6wTGzFy15727v3fOntf3zF9Dh7Y5GcuTnZXF6J9cT8+Te7Bjx06G/OinnN/7LHqccDz3j7+d30x4IGNZ9lVdXc1dd9xH8Zp15Oa258UFz/Lm68vYuL4stEyxWIwHJo6j/6VDKS+vZNnSOcycNY+Skg3Kk+E8LWqP4ezjOnJYuzb7/czdmVdcQf+vFWQszzEdj6LnyT0AyM1tzwnHF7Dto084sdtxdD++a8Zy7M9H2z6meM06AHbs2Enp+jI6dTk21EyFvc+itHQTZWWbqaqqYvr0lxk0sJ/yhJAnbXsMZnYKMBjIBxzYCsxw95J0tdmQt7d8wtG5bTn+qA5hNE9F5TZKNpRy+tdODqX9huQXdKHnaafw7qq1oebIy+/MlvKte5bLKyop7H2W8oSQJy17DGb2C+A5wIDlwIrE6z+Y2a0NrDfczFaa2conFq5u1kxzi7ZkdG+hrp07d/Gvt93JL356Ax1yc0PJUJ/2ue2YNGUC48b8lu3bd4SaxSw4mVCYzz1pzXnStcfwI+Br7l5V900zuxcoAv5jfyu5+2RgMjTv1G67a2pY8Ket/OGHFzfXJpNWtXs3o267k+/0vZhL+lyQ8fYbkp2dzaQpE5jxwivMm70w7DhUlFdS0DVvz3LX/C5UVm5TnhDypOscQw2Qt5/3uyQ+y6i3yj6k+9GH0umw9hlt19359V33c8LxBVx75fcy2nYyxt9/O6Xry5jyyNSwowCwYuVqevToTrduBeTk5DBkyGBmzpqnPCHkSdcewyhggZltALYk3jsO6AHclKY2ufXF5ax8/yM+2/UVfR+Yw79c1JPLzuzG3OJy+vfM/Mm+d9YUMXPuAk46sRuXXxu/tDTyhmv5qqqKu+57mL989jkjRt/BKSedwOT7xmU029nnnMllVwxgXdEGZiycBsA94x7ijflvZjRHXdXV1YwcNYY5s6eRFYvx5FPPU1wczuXc1p7H0nWMYmYxoJD4yUcDyoEV7l6dzPqaJbphmiVamkN9s0Sn7aqEu9cAy9K1fRFJnxZ1H4OINA8VBhEJUGEQkQAVBhEJUGEQkQAVBhEJUGEQkQAVBhEJUGEQkQAVBhEJUGEQkQAVBhEJSNvoylRlt8mPVLDuh3cOO8JeojaaMWr9A9HroyMOidbsXQAff7F+v6MrtccgIgEqDCISoMIgIgEqDCISoMIgIgEqDCISoMIgIgEqDCISoMIgIgEqDCISoMIgIgEqDCISoMIgIgEqDCIS0KILQ7++fShau4h1xUu4ZfSNoWbpnNeJZ158lLlvvsCcxdO5dvjQUPNAtPoH1EeNmfjQeEpKl7J42ay0t9Vi52OIxWKUFC2m/6VDKS+vZNnSOQy7egQlJRuatL1U5xs4plNHjunUkeI168jNbc+LC55lxDU/Z+P6siZtL9W5BqLWP9Dy+yjV+RjOO78XO3bs5KFH7+ab5w5IaVu1Wt18DIW9z6K0dBNlZZupqqpi+vSXGTSwX2h5Ptr2McVr1gGwY8dOSteX0anLsaHliVr/gPqoMUv/dyWffvp5RtrKeGEws+sy0U5efme2lG/ds1xeUUleXjRmGcov6ELP007h3VVrQ8sQ5f4B9VHYwthj+E19H5jZcDNbaWYra2p2pNSIWXAPKQqHTe1z2zFpygTGjfkt27en9jumIqr9A+qjKMhOx0bNbE19HwGd6lvP3ScDkyH1cwwV5ZUUdM3bs9w1vwuVldtS2WTKsrOzmTRlAjNeeIV5sxeGmiWK/QPqo6hI1x5DJ+AaYOB+vj5JU5t7WbFyNT16dKdbtwJycnIYMmQwM2fNy0TT9Rp//+2Uri9jyiNTQ80B0ewfUB9FRVr2GIBZQAd3X73vB2b2epra3Et1dTUjR41hzuxpZMViPPnU8xQXr89E0/t19jlnctkVA1hXtIEZC6cBcM+4h3hj/puh5Ila/4D6qDGTf38vF1xYyFFHH8makkX85/gHmPrMC2lpq8VermxuUZsePWpTo0etfyB6faTp40XkoKbCICIBKgwiEqDCICIBKgwiEqDCICIBKgwiEqDCICIBKgwiEqDCICIBKgwiEqDCICIBGkR1kIragJzP/hrehCrSdLu/qtjvIKp6h12b2VENbdDd/5JqKBGJpobmY1gFOPFZl/blwAlpSSQioau3MLh790wGEZHoaPTko8UNM7PbE8vHmVlh+qOJSFiSuSrxO+A84AeJ5S+Bh9KWSERCl8ycj+e4+zfM7B0Ad//UzNqkOZeIhCiZPYYqM8sifsIRMzsGqElrKhEJVTKF4QHgRaCTmY0DlgDj05pKRELV6KGEu081s1XAtxNvfdfdS9IbS0TClOxzJdoDtYcT7dIXR0SiIJnLlb8GngKOAjoCU8xsTLqDiUh4Gh0rYWYlwFnu/tfEcjvgbXc/NZ3BNFaiYRorIc2hvrESyZx83AQcUme5LVDaDJlEJKIaGkT1IPFzCv8HFJnZa4nlS4hfmRCRFqqhPYaVxAdSvQj8ClgIvA7cBryS9mTNoF/fPhStXcS64iXcMvrGsONELs/Eh8ZTUrqUxctmhR1lj6j1UWvN02LnY4jFYpQULab/pUMpL69k2dI5DLt6BCUlG5orYqh5muMcw3nn92LHjp089OjdfPPcASltqznOMbT0f7Mo5mnyOQYzO8nMXjCzYjP7c+1XEuudYmbfNrMO+7zfP/nYTVfY+yxKSzdRVraZqqoqpk9/mUED+2Wi6YMiD8DS/13Jp59+HmqGuqLWR605TzInH6cADwO7gYuBp4FnGlrBzH4KvAz8BFhrZoPrfJyRuybz8juzpXzrnuXyikry8sJ7VHvU8kRR1PqoNedJpjC0c/cFxA873nf3scC3GlnneuBsd/8u0Ae43cxGJj7b764LgJkNN7OVZraypia1XVOzYDNhHjZFLU8URa2PWnOeZO58/KuZxYANZnYTUAEc28g6We6+HcDdN5lZH+AFMzueBgqDu08GJkPq5xgqyisp6Jq3Z7lrfhcqK7elssmURC1PFEWtj1pznmT2GEYRvyX6p8DZwNXAtY2s84GZnVm7kCgSA4jfOXla06IemBUrV9OjR3e6dSsgJyeHIUMGM3PWvEw0fVDkiaKo9VFrzpPMIKoViZfbgeuS3O41xM9J1N3ObuAaM3v0gBI2UXV1NSNHjWHO7GlkxWI8+dTzFBevz0TTB0UegMm/v5cLLizkqKOPZE3JIv5z/ANMfeaF0PJErY9ac556L1ea2UwSczDsj7sPSkuiBN0S3TDdEi3N4YCnjwd+m6YsIhJxDc0S/UYmg4hIdOgRdSISoMIgIgEqDCIS0NCw61CvSohIeJK5KvE9oDPwbGJ5KPHJW0SkhWr0qoSZ/bu7X1Tno5lmtijtyUQkNMmcYzjGzPY82drMugPHpC+SiIQtmUFU/wq8XmcOhm7ADWlLJCKhS2asxFwzOwk4JfHWOnf/v/TGEpEwJTODU3tgNHCTu78LHGdmqc0DJiKRluwMTl8B5yWWy4E705ZIREKXzDmGE939CjMbCuDuu2x/U8lIRkVtNOM3OvYIO0LA2x9vDDvCQSuZPYavEk+fcgAzO5H4syZEpIVKZo9hLDAXKDCzqcAFJD9hi4gchJK5KjHPzFYB5xKfr3Gku3+c9mQiEppkrkoscPdP3H22u89y94/NbEEmwolIOBoaRHUI8UlgO5rZkfxtdufDgLz61hORg19DhxI3EJ8hOo/4MyxrC8MXwENpziUiIWpoENVEYKKZ/cTdH8xgJhEJWTKXK2vM7IjaBTM70sxGpDGTiIQsmcJwvbt/Vrvg7p8SfwSdiLRQyRSGWN07Hc0sC2iTvkgiErZkbnB6FZhuZo8Qv/vxn4nf8CQiLVQyheEXxK9Q/AvxKxPzgMfTGUpEwpXMnY81wMOJLxFpBeo9x2Bm0xPf3zOzNft+ZS5i0/Xr24eitYtYV7yEW0bfGHYc5WlEm7ZtmDL7Eaa+9gTPLXyS628Of0hO1PooU3kaeqhtF3evNLPj9/e5u7+ftlSk/lDbWCxGSdFi+l86lPLySpYtncOwq0dQUrKhuSIqTx3NNey6Xft27Nq5i6zsLB57aRL3/vpB1r5d3KRtpTrsuqX/m0H9D7Wtd4/B3SsT39/f31djDZpZoZn1TrzuaWY/M7NLm/oLHKjC3mdRWrqJsrLNVFVVMX36ywwa2C9TzStPE+3auQuA7JxssnOyqe8PVyZErY8ymaehQ4kvzeyL+r4a2qiZ3QE8ADxsZncBk4AOwK1mdluz/gb1yMvvzJbyrXuWyysqycvrnImmlScFsViMZ197nFfXvMTyRSspeqcktCxR66NM5mnoluhDAczs34APgGeIX5W4Cji0ke3+I3Am0Daxbld3/8LMJgBvAeP2t5KZDQeGA1jW4cRiuQf0y+yzrcB7Yf71UZ7k1NTUMOySH9PhsA7c/cSdnHByd/78p7JQskStjzKZJ5kbnPq5++/c/Ut3/8LdHwYub2Sd3e5e7e47gVJ3/wLi08IBNfWt5O6T3b2Xu/dKpSgAVJRXUtD1b4NAu+Z3obJyW0rbVJ7M2f7Fdt5e+g7nXVwYWoao9VEm8yRTGKrN7CozyzKzmJldBVQ3ss5XidmlAc6ufdPMDqeBwtCcVqxcTY8e3enWrYCcnByGDBnMzFnzMtG08jTREUcdTofDOgDQ9pA2FH6zF+9v3Bxanqj1USbzJHOD0w+AiYkvB95MvNeQi2qfPZG4D6JWDnBtE3IesOrqakaOGsOc2dPIisV48qnnKS5en4mmlaeJOnY6mjsm/opYLEYsZsyf+TpL5i8NLU/U+iiTeeq9XBm2VC9XSmZpluiD0wFfrqxlZn9nZgvMbG1i+XQzG9PcAUUkOpI5x/AY8EugCsDd1wBXpjOUiIQrmcLQ3t2X7/Pe7nSEEZFoSKYwfJx4yEztA2f+EahMayoRCVUyVyVuBCYDp5hZBVBG/CYnEWmhGiwMZhYDern735tZLhBz9y8zE01EwtLgoUTiHoSbEq93qCiItA7JnGN4zcxuNrMCMzuq9ivtyUQkNMmcY/hh4nvdWSEcOKH544hIFCQztVv3TAQRkehotDAknmE5AriQ+J7CYuARd/9rmrOJSEiSOZR4GvgSqH1M3VDiczN8P12hRCRcyRSGk939jDrLC83s3XQFEpHwJVMY3jGzc919GYCZnUN86HWr0v3w8Kc9q6vs8w/CjrCXKI5kjOKIz4NFMoXhHOAaM6udMeM4oMTM3gPc3U9PWzoRCUUyhaF/2lOISKQkc7kyrc+PEJHoSebORxFpZVQYRCRAhUFEAlQYRCRAhUFEAlQYRCRAhUFEAlQYRCRAhUFEAlQYRCSgRReGfn37ULR2EeuKl3DL6BsbXyGNOud14pkXH2Xumy8wZ/F0rh0+NNQ8EK3+qRWlTG3atmHK7EeY+toTPLfwSa6/+bpWk6fFPtQ2FotRUrSY/pcOpby8kmVL5zDs6hGUlGxo0vZSHXZ9TKeOHNOpI8Vr1pGb254XFzzLiGt+zsb1ZU3aXqrDrpu7f5pDc2dqjmHX7dq3Y9fOXWRlZ/HYS5O499cPsvbt4pS3G5U8y7e+0bSH2h6sCnufRWnpJsrKNlNVVcX06S8zaGC/0PJ8tO1jitesA2DHjp2Uri+jU5djQ8sTtf6JaqZdO3cBkJ2TTXZONmH/Ic1UnowVBjN7OlNtAeTld2ZL+dY9y+UVleTlRWOylfyCLvQ87RTeXbU2tAxR7J8oZorFYjz72uO8uuYlli9aSdE7Ja0iTzLzMRwwM5ux71vAxWZ2BIC7D6pnveHAcADLOpxYLDeVDIH3wq72AO1z2zFpygTGjfkt27fvCC1HFPsniplqamoYdsmP6XBYB+5+4k5OOLk7f/5T0w7/DqY8aSkMQFegGHic+MzSBvQC7mloJXefTPw5mSmfY6gor6Sga97fAuV3obJyWyqbTFl2djaTpkxgxguvMG/2wlCzRLF/opip1vYvtvP20nc47+LCUAtDpvKk61CiF7AKuA343N1fB3a5+xvu/kaa2tzLipWr6dGjO926FZCTk8OQIYOZOWteJpqu1/j7b6d0fRlTHpkaag6IZv9ELdMRRx1Oh8M6AND2kDYUfrMX72/c3MhaLSNPWvYYEs+8vM/M/ivxfVu62qpPdXU1I0eNYc7saWTFYjz51PMUF6/PZIS9nH3OmVx2xQDWFW1gxsJpANwz7iHemB/OvLpR658oZurY6WjumPgrYrEYsZgxf+brLJm/tFXkycjlSjP7DnCBu/8q2XVSPZRobpol+uCjWaIbV9/lyoz8FXf32cDsTLQlIqlrsfcxiEjTqTCISIAKg4gEqDCISIAKg4gEqDCISIAKg4gEqDCISIAKg4gEqDCISIAKg4gEqDCISEBGh0IfzDSasWGXdDo97AgBr21bE3aEvUSxj+qjPQYRCVBhEJEAFQYRCVBhEJEAFQYRCVBhEJEAFQYRCVBhEJEAFQYRCVBhEJEAFQYRCVBhEJEAFQYRCVBhEJGAFl0Y+vXtQ9HaRawrXsIto28MO47yJCEWizHplUmMnTI27ChA6+2jFlsYYrEYD0wcx4CBwzjtjIu54orvcuqpJylPRPPUGvyjwWzeuDnsGEDr7qOMFAYzu9DMfmZmfTPRHkBh77MoLd1EWdlmqqqqmD79ZQYN7Jep5pWnCTp27kjhtwp59Q+vhpqjVmvuo7QUBjNbXuf19cAk4FDgDjO7NR1t7isvvzNbyrfuWS6vqCQvr3MmmlaeJrph7A08Mf4JampqQs1RqzX3Ubr2GHLqvB4OXOLuvwH6AlfVt5KZDTezlWa2sqZmR0oBzCzwnruntM1UKE/DCr9dyGeffMbG9zaGlmFfrbmP0jXnY8zMjiReeMzdPwJw9x1mtru+ldx9MjAZILtNfkr/AhXllRR0zduz3DW/C5WV21LZZEqUp2E9e/Xk3EvOpffFvclpm0P7Q9szeuJoJoycEFqm1txHlo4KaGabgBrAAAfOd/cPzKwDsMTdz2xsG6kWhqysLEqKFtO3/xVUVHzAsqVzuPqaGykuXp/KZpWnHs050elp557G5Tdcztjrxqa0nVQng20NffTKlleCu0WkaY/B3bvV81ENcFk62txXdXU1I0eNYc7saWTFYjz51POh/U+oPAen1txHadljaA6p7jFIZkVxanRNH9+4+vYYWux9DCLSdCoMIhKgwiAiASoMIhKgwiAiASoMIhKgwiAiASoMIhKgwiAiASoMIhKgwiAiASoMIhKgwiAiAZEdXdlczGx4YgKYyIhaJuVpWNTyQPoztYY9huFhB9iPqGVSnoZFLQ+kOVNrKAwicoBUGEQkoDUUhkgdGyZELZPyNCxqeSDNmVr8yUcROXCtYY9BRA6QCoOIBLTowmBm/c3sT2a2MVOPxmsgy+/N7EMzWxtmjlpmVmBmC82sxMyKzGxkBDIdYmbLzezdRKbfhJ0JwMyyzOwdM5sVgSybzOw9M1ttZivT1k5LPcdgZlnAeuASoBxYAQx19+KQ8lwEbAeedvevh5FhnzxdgC7u/raZHQqsAr4bVv8kMhmQ6+7bzSwHWAKMdPdlYWVK5PoZ0As4zN0HhJxlE9DL3T9OZzsteY+hENjo7n9296+A54DBYYVx90XAX8Jqf1/uXunubydefwmUAPkhZ3J3355YzEl8hfqXy8y6At8BHg8zR6a15MKQD2yps1xOyP/hR5WZdQPOAt4KN8me3fbVwIfAa+4edqb7gVuIP0UtChyYZ2arzCxtdz+25MKwvyfstMzjphQknif638Aod/8i7DzuXp14tmlXoNDMQjvsMrMBwIfuviqsDPtxgbt/A/gH4MbEIWqza8mFoRwoqLPcFdgaUpZIShzH/zcw1d3/J+w8dbn7Z8DrQP8QY1wADEoc1z8HfMvMng0xD+6+NfH9Q+BF4ofMza4lF4YVwElm1t3M2gBXAjNCzhQZiRN9TwAl7n5v2HkAzOwYMzsi8bod8PfAurDyuPsv3b1r4iHNVwJ/dPdhYeUxs9zEiWLMLBfoC6TlKleLLQzuvhu4CXiV+Im16e5eFFYeM/sDsBQ42czKzexHYWVJuAC4mvhfwdWJr0tDztQFWGhma4gX9tfcPfRLhBHSCVhiZu8Cy4HZ7j43HQ212MuVItJ0LXaPQUSaToVBRAJUGEQkQIVBRAJUGEQkQIWhFTGzI8xsRBq3/09mNqmRnxlrZjcf4Ha3N/5T0pxUGFqXI4D9FobEaFQRQIWhtfkP4MTEzUwTzKxPYk6GacB7Ztat7nwRZnazmY1NvD7RzOYmBu8sNrNTGmrIzAaa2VuJeQzmm1mnOh+fYWZ/NLMNZnZ9nXVGm9kKM1sTlbkYWqvssANIRt0KfD0xSAkz60P8Xvuvu3tZYpRlfSYD/+zuG8zsHOB3wLca+PklwLnu7mb2Y+IjFH+e+Ox04FwgF3jHzGYDXwdOSuQxYIaZXZQYri4ZpsIgy929rKEfSIzAPB/4r/gQCwDaNrLdrsDziQlh2gB123jZ3XcBu8xsIfFicCHxe//fSfxMB+KFQoUhBCoMsqPO693sfXh5SOJ7DPisdk8jSQ8C97r7jMSeydg6n+17H74T30u4y90fPYA2JE10jqF1+RI4tIHPtwHHmtnRZtYWGACQmKehzMy+D/GRmWZ2RiNtHQ5UJF5fu89ngxPzOx4N9CE+YOpV4IeJvRPMLN/Mjk3+V5PmpD2GVsTdPzGzNxMnGF8BZu/zeZWZ/RvxmZzK2HvI81XAw2Y2hviUa88B7zbQ3Fjihx4VwDKge53PlifaPg7498QcA1vN7FRgaeJwZTswjPhMTpJhGl0pIgE6lBCRABUGEQlQYRCRABUGEQlQYRCRABUGEQlQYRCRgP8HuIzI65YaGC0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning using GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=0.003511191734215131)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}\n",
    "\n",
    "nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "nbModel_grid.fit(X_train, y_train)\n",
    "print(nbModel_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 7 1 1 2 1 1 1 6 6 1 2 7 1 1 1 5 1 1 1 5 7 1 7 1 1 7 1 1 1 6 1 1 2 1 7 1\n",
      " 1 1 1 1 5 1 1 1 1 1 7 1 7 1 2 1 6 7 1 1 7 5 1 2 1 7 1 6]\n"
     ]
    }
   ],
   "source": [
    "y_pred = nbModel_grid.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  1  0  0  0  0]\n",
      " [21  2  0  0  2  0]\n",
      " [ 3  0  0  0  0  0]\n",
      " [ 0  2  0  4  0  3]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  0  0  0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5076923076923077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set is fold number : 1\n",
      "Accuracy score is : 0.5 \n",
      "\n",
      "Confusion Matrix is :\n",
      "\n",
      " [[9 0 0 0 1 0]\n",
      " [5 2 0 1 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]]\n",
      "\n",
      "Classification Report is as follows :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.60      0.90      0.72        10\n",
      "         2.0       0.67      0.25      0.36         8\n",
      "         3.0       0.00      0.00      0.00         1\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        22\n",
      "   macro avg       0.21      0.19      0.18        22\n",
      "weighted avg       0.52      0.50      0.46        22\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Test set is fold number : 2\n",
      "Accuracy score is : 0.36363636363636365 \n",
      "\n",
      "Confusion Matrix is :\n",
      "\n",
      " [[6 0 0 0 0 0]\n",
      " [6 1 0 0 0 0]\n",
      " [4 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 2 0 0 0 0]]\n",
      "\n",
      "Classification Report is as follows :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.38      1.00      0.55         6\n",
      "         2.0       0.20      0.14      0.17         7\n",
      "         3.0       0.00      0.00      0.00         4\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       1.00      1.00      1.00         1\n",
      "         7.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.36        22\n",
      "   macro avg       0.26      0.36      0.29        22\n",
      "weighted avg       0.21      0.36      0.25        22\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Test set is fold number : 3\n",
      "Accuracy score is : 0.4090909090909091 \n",
      "\n",
      "Confusion Matrix is :\n",
      "\n",
      " [[6 0 0 0 0]\n",
      " [7 2 0 0 0]\n",
      " [2 0 0 0 0]\n",
      " [0 1 0 1 0]\n",
      " [0 0 0 3 0]]\n",
      "\n",
      "Classification Report is as follows :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.40      1.00      0.57         6\n",
      "         2.0       0.67      0.22      0.33         9\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       0.25      0.50      0.33         2\n",
      "         7.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.41        22\n",
      "   macro avg       0.26      0.34      0.25        22\n",
      "weighted avg       0.40      0.41      0.32        22\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Test set is fold number : 4\n",
      "Accuracy score is : 0.45454545454545453 \n",
      "\n",
      "Confusion Matrix is :\n",
      "\n",
      " [[6 1 0 0 0 0]\n",
      " [5 1 0 2 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [1 0 0 1 1 2]]\n",
      "\n",
      "Classification Report is as follows :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.46      0.86      0.60         7\n",
      "         2.0       0.50      0.12      0.20         8\n",
      "         3.0       0.00      0.00      0.00         1\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       0.50      1.00      0.67         1\n",
      "         7.0       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.45        22\n",
      "   macro avg       0.41      0.40      0.34        22\n",
      "weighted avg       0.58      0.45      0.42        22\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Test set is fold number : 5\n",
      "Accuracy score is : 0.47619047619047616 \n",
      "\n",
      "Confusion Matrix is :\n",
      "\n",
      " [[8 1 0 0 0]\n",
      " [4 0 0 0 0]\n",
      " [2 0 1 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 3 0]]\n",
      "\n",
      "Classification Report is as follows :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.57      0.89      0.70         9\n",
      "         2.0       0.00      0.00      0.00         4\n",
      "         3.0       1.00      0.25      0.40         4\n",
      "         6.0       0.20      1.00      0.33         1\n",
      "         7.0       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.48        21\n",
      "   macro avg       0.35      0.43      0.29        21\n",
      "weighted avg       0.44      0.48      0.39        21\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Test set is fold number : 6\n",
      "Accuracy score is : 0.5714285714285714 \n",
      "\n",
      "Confusion Matrix is :\n",
      "\n",
      " [[7 0 0 0 0 0]\n",
      " [5 3 0 0 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 3 1]]\n",
      "\n",
      "Classification Report is as follows :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.54      1.00      0.70         7\n",
      "         2.0       1.00      0.38      0.55         8\n",
      "         3.0       0.00      0.00      0.00         1\n",
      "         5.0       1.00      1.00      1.00         1\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "         7.0       1.00      0.25      0.40         4\n",
      "\n",
      "    accuracy                           0.57        21\n",
      "   macro avg       0.59      0.44      0.44        21\n",
      "weighted avg       0.80      0.57      0.56        21\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Test set is fold number : 7\n",
      "Accuracy score is : 0.3333333333333333 \n",
      "\n",
      "Confusion Matrix is :\n",
      "\n",
      " [[5 2 0 0 0 0]\n",
      " [4 0 0 2 0 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 0 0 1 1]\n",
      " [0 0 0 0 2 1]]\n",
      "\n",
      "Classification Report is as follows :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.50      0.71      0.59         7\n",
      "         2.0       0.00      0.00      0.00         6\n",
      "         3.0       0.00      0.00      0.00         1\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.33      0.50      0.40         2\n",
      "         7.0       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.33        21\n",
      "   macro avg       0.22      0.26      0.23        21\n",
      "weighted avg       0.27      0.33      0.29        21\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Test set is fold number : 8\n",
      "Accuracy score is : 0.42857142857142855 \n",
      "\n",
      "Confusion Matrix is :\n",
      "\n",
      " [[4 1 1 0 0 0]\n",
      " [5 3 0 1 1 0]\n",
      " [1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 2 0]]\n",
      "\n",
      "Classification Report is as follows :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.40      0.67      0.50         6\n",
      "         2.0       0.75      0.30      0.43        10\n",
      "         3.0       0.00      0.00      0.00         1\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       0.40      1.00      0.57         2\n",
      "         7.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.43        21\n",
      "   macro avg       0.26      0.33      0.25        21\n",
      "weighted avg       0.51      0.43      0.40        21\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Test set is fold number : 9\n",
      "Accuracy score is : 0.19047619047619047 \n",
      "\n",
      "Confusion Matrix is :\n",
      "\n",
      " [[1 1 1 0 0 0]\n",
      " [7 0 0 0 1 1]\n",
      " [2 0 0 0 0 0]\n",
      " [0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 3 2]]\n",
      "\n",
      "Classification Report is as follows :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.10      0.33      0.15         3\n",
      "         2.0       0.00      0.00      0.00         9\n",
      "         3.0       0.00      0.00      0.00         2\n",
      "         5.0       1.00      0.50      0.67         2\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "         7.0       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.19        21\n",
      "   macro avg       0.29      0.21      0.22        21\n",
      "weighted avg       0.27      0.19      0.20        21\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Test set is fold number : 10\n",
      "Accuracy score is : 0.5714285714285714 \n",
      "\n",
      "Confusion Matrix is :\n",
      "\n",
      " [[8 0 1 0 0 0]\n",
      " [4 2 0 1 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 1 0]]\n",
      "\n",
      "Classification Report is as follows :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.67      0.89      0.76         9\n",
      "         2.0       0.50      0.29      0.36         7\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         5.0       0.00      0.00      0.00         2\n",
      "         6.0       0.67      1.00      0.80         2\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.57        21\n",
      "   macro avg       0.31      0.36      0.32        21\n",
      "weighted avg       0.52      0.57      0.52        21\n",
      "\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\VIBHU GOYAL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## making our folds\n",
    "## Randomly Shuffle the data\n",
    "df=df.sample(frac=1)\n",
    "\n",
    "k = 10\n",
    "folds = np.array_split(df, k)\n",
    "\n",
    "## function to perform our accuracy testing\n",
    "\n",
    "def perform(Train, test):\n",
    "    # remove labels from data\n",
    "    \"\"\"\n",
    "    train_labels = train_set.pop('class').values\n",
    "    test_labels = test_set.pop('class').values\n",
    "    clf.fit(train_set, train_labels)\n",
    "    \n",
    "    print(\"Accuracy Score is:\",clf.score(test_set, test_labels))\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train=Train.values[:,:7]\n",
    "    X_test=Train.values[:,7]\n",
    "    y_train=test.values[:,:7]\n",
    "    y_test=test.values[:,7]\n",
    "    \n",
    "    gnb=GaussianNB()\n",
    "    gnb.fit(X_train,X_test)\n",
    "    y_pred=gnb.predict(y_train)  # getting predictions from the classifier\n",
    "    \n",
    "    \n",
    "    print(\"Accuracy score is :\",accuracy_score(y_test,y_pred),'\\n') # calculating accuracy\n",
    "    print(\"Confusion Matrix is :\\n\\n\",confusion_matrix(y_test,y_pred))\n",
    "    print(\"\\nClassification Report is as follows :\\n\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "for i in range(k):\n",
    "    train = folds.copy() ##you wanna work on a copy of your array\n",
    "    test = folds[i]\n",
    "    del train[i]\n",
    "    train = pd.concat(train, sort=False)\n",
    "    print(\"Test set is fold number :\",i+1)\n",
    "    perform(train.copy(), test.copy()) ##do the fitting, here you also want to copy\n",
    "    print(\"------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "##In this function you remove the label column from your sets and fit the scikit-classifier (clf) and then return the prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
